{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d867484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18cf8dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/26 19:13:55 WARN Utils: Your hostname, murats-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.68.101 instead (on interface en0)\n",
      "23/02/26 19:13:55 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/26 19:13:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Datamanipulation\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e64796c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.68.101:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Datamanipulation</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x11307dc70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cb29770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# read our data - lives in a csv file\n",
    "\n",
    "df = spark.read.option(\"header\",\"true\").csv(\"Sample - EU Superstore.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6899efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Row ID: string (nullable = true)\n",
      " |-- Order ID: string (nullable = true)\n",
      " |-- Order Date: string (nullable = true)\n",
      " |-- Ship Date: string (nullable = true)\n",
      " |-- Ship Mode: string (nullable = true)\n",
      " |-- Customer ID: string (nullable = true)\n",
      " |-- Customer Name: string (nullable = true)\n",
      " |-- Segment: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Product ID: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Sub-Category: string (nullable = true)\n",
      " |-- Product Name: string (nullable = true)\n",
      " |-- Sales: string (nullable = true)\n",
      " |-- Quantity: string (nullable = true)\n",
      " |-- Discount: string (nullable = true)\n",
      " |-- Profit: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c24992ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "795"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"Customer ID\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c800030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2827"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many rows of the EU Superstore dataset have the country being France\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "df = df.withColumn(\"Profit\", df.Profit.cast(IntegerType()))\n",
    "\n",
    "frdf = df.filter(df[\"Country\"] == \"France\")\n",
    "frdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "648e5f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+----------+----------+--------------+-----------+----------------+-----------+-----------------+--------------------+-------+-------+---------------+---------------+------------+--------------------+--------+--------+--------+------+\n",
      "|Row ID|       Order ID|Order Date| Ship Date|     Ship Mode|Customer ID|   Customer Name|    Segment|             City|               State|Country| Region|     Product ID|       Category|Sub-Category|        Product Name|   Sales|Quantity|Discount|Profit|\n",
      "+------+---------------+----------+----------+--------------+-----------+----------------+-----------+-----------------+--------------------+-------+-------+---------------+---------------+------------+--------------------+--------+--------+--------+------+\n",
      "|    12|ES-2015-2510515|20/06/2015|20/06/2015|      Same Day|   LH-17155|Logan Haushalter|   Consumer|       Le Bouscat|Aquitaine-Limousi...| France|Central|OFF-AP-10002330|Office Supplies|  Appliances|Hamilton Beach St...|2443.905|       5|     0.1|   760|\n",
      "|    14|ES-2015-2510515|20/06/2015|20/06/2015|      Same Day|   LH-17155|Logan Haushalter|   Consumer|       Le Bouscat|Aquitaine-Limousi...| France|Central|TEC-PH-10002898|     Technology|      Phones|Samsung Smart Pho...|2167.296|       4|    0.15|   790|\n",
      "|    16|ES-2016-4380115|16/02/2016|20/02/2016|Standard Class|   KC-16540| Kelly Collister|   Consumer|       Strasbourg|Alsace-Champagne-...| France|Central|OFF-ST-10003931|Office Supplies|     Storage|Smead Trays, Wire...| 128.385|       3|     0.1|     4|\n",
      "|    18|ES-2016-4380115|16/02/2016|20/02/2016|Standard Class|   KC-16540| Kelly Collister|   Consumer|       Strasbourg|Alsace-Champagne-...| France|Central|OFF-LA-10001676|Office Supplies|      Labels|Hon Removable Lab...|    8.16|       1|       0|     1|\n",
      "|    21|ES-2017-1872792|14/08/2017|16/08/2017|   First Class|   BF-11275|   Beth Fritzler|  Corporate|           Thiais|       Ile-de-France| France|Central|OFF-BI-10001249|Office Supplies|     Binders|Acco Hole Reinfor...|   14.04|       2|       0|     7|\n",
      "|    36|ES-2016-3284813|31/05/2016|05/06/2016|Standard Class|   SC-20020|      Sam Craven|   Consumer|         Chaville|       Ile-de-France| France|Central|OFF-AR-10000785|Office Supplies|         Art|BIC Sketch Pad, W...|  155.52|       3|       0|    23|\n",
      "|    37|ES-2016-3284813|31/05/2016|05/06/2016|Standard Class|   SC-20020|      Sam Craven|   Consumer|         Chaville|       Ile-de-France| France|Central|OFF-ST-10002151|Office Supplies|     Storage|     Eldon Box, Blue|   46.17|       5|     0.1|     8|\n",
      "|    38|ES-2016-3284813|31/05/2016|05/06/2016|Standard Class|   SC-20020|      Sam Craven|   Consumer|         Chaville|       Ile-de-France| France|Central|OFF-LA-10004929|Office Supplies|      Labels|Novimex Color Cod...|   37.26|       3|       0|     8|\n",
      "|    47|ES-2014-5235241|27/08/2014|28/08/2014|      Same Day|   TB-21175|   Thomas Boland|  Corporate|          Taverny|       Ile-de-France| France|Central|OFF-SU-10004818|Office Supplies|    Supplies|Stiletto Trimmer,...|    84.3|       2|       0|    28|\n",
      "|    49|ES-2014-5235241|27/08/2014|28/08/2014|      Same Day|   TB-21175|   Thomas Boland|  Corporate|          Taverny|       Ile-de-France| France|Central|OFF-AR-10000319|Office Supplies|         Art|Binney & Smith Ca...|  157.86|       3|       0|    29|\n",
      "|    53|ES-2017-3937023|07/11/2017|11/11/2017|Standard Class|   JE-15715|      Joe Elijah|   Consumer|         Viroflay|       Ile-de-France| France|Central|OFF-AR-10003829|Office Supplies|         Art|Stanley Markers, ...|   46.92|       2|       0|    15|\n",
      "|    54|ES-2017-3937023|07/11/2017|11/11/2017|Standard Class|   JE-15715|      Joe Elijah|   Consumer|         Viroflay|       Ile-de-France| France|Central|OFF-AR-10003217|Office Supplies|         Art|Sanford Highlight...|   34.02|       2|       0|    14|\n",
      "|    73|ES-2017-4856325|25/04/2017|26/04/2017|   First Class|   GH-14410|     Gary Hansen|Home Office|            Paris|       Ile-de-France| France|Central|TEC-AC-10000140|     Technology| Accessories|Enermax Numeric K...|  402.78|       7|       0|    92|\n",
      "|    74|ES-2017-1193193|21/05/2017|23/05/2017|   First Class|   EN-13780|   Edward Nazzal|   Consumer|            Dijon|Bourgogne-Franche...| France|Central|FUR-CH-10001153|      Furniture|      Chairs|Harbour Creations...| 173.097|       3|     0.1|    69|\n",
      "|    80|ES-2017-1016124|08/02/2017|13/02/2017|Standard Class|   MC-18100|   Mick Crebagga|   Consumer|            Rouen|            Normandy| France|Central|OFF-BI-10004628|Office Supplies|     Binders|Cardinal Binder, ...|   30.66|       2|       0|     1|\n",
      "|   100|ES-2016-5581781|28/08/2016|01/09/2016|Standard Class|   MV-18190|  Mike Vittorini|   Consumer|         Argentan|            Normandy| France|Central|FUR-FU-10003069|      Furniture| Furnishings|Deflect-O Photo F...|  195.72|       4|       0|    27|\n",
      "|   104|ES-2015-1915501|19/01/2015|21/01/2015|  Second Class|   JB-15400|Jennifer Braxton|  Corporate|Saint-Genis-Laval|Auvergne-Rhône-Alpes| France|Central|OFF-AR-10001176|Office Supplies|         Art|Sanford Pens, Wat...|   42.84|       3|       0|    19|\n",
      "|   107|ES-2016-3029399|27/09/2016|28/09/2016|   First Class|   KL-16555|   Kelly Lampkin|  Corporate|            Paris|       Ile-de-France| France|Central|OFF-PA-10002396|Office Supplies|       Paper|Eaton Memo Slips,...|   35.76|       2|       0|     9|\n",
      "|   112|ES-2017-2774938|01/01/2017|03/01/2017|  Second Class|   FH-14350|     Fred Harton|   Consumer|           Pantin|       Ile-de-France| France|Central|OFF-LA-10003132|Office Supplies|      Labels|Smead Round Label...|    13.8|       2|       0|     4|\n",
      "|   121|ES-2014-1720401|18/02/2014|24/02/2014|Standard Class|   KH-16630|      Ken Heidel|  Corporate|           Beaune|Bourgogne-Franche...| France|Central|OFF-FA-10003463|Office Supplies|   Fasteners|OIC Thumb Tacks, ...|   34.56|       3|       0|    13|\n",
      "+------+---------------+----------+----------+--------------+-----------+----------------+-----------+-----------------+--------------------+-------+-------+---------------+---------------+------------+--------------------+--------+--------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2277"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# of those, how many are profitable?\n",
    "\n",
    "profitable = frdf.filter(frdf[\"Profit\"] > 0)\n",
    "profitable.show()\n",
    "profitable.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca611b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|Discount|\n",
      "+--------+\n",
      "|       0|\n",
      "|     0.1|\n",
      "|    0.15|\n",
      "|     0.2|\n",
      "|     0.3|\n",
      "|    0.35|\n",
      "|     0.4|\n",
      "|    0.45|\n",
      "|     0.5|\n",
      "|     0.6|\n",
      "|    0.65|\n",
      "|     0.7|\n",
      "|     0.8|\n",
      "|    0.85|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how any different discount brackets exist? what are they?\n",
    "brackets = df.select(\"Discount\").distinct().orderBy(\"Discount\")\n",
    "brackets.show()\n",
    "brackets.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2e1f9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|Discount|total_profit|\n",
      "+--------+------------+\n",
      "|       0|      380803|\n",
      "|     0.1|      126392|\n",
      "|    0.15|       24623|\n",
      "|     0.2|        2174|\n",
      "|     0.3|        -756|\n",
      "|    0.35|       -9108|\n",
      "|     0.4|      -21259|\n",
      "|    0.45|       -1102|\n",
      "|     0.5|      -96104|\n",
      "|     0.6|      -20460|\n",
      "|    0.65|       -6213|\n",
      "|     0.7|       -5493|\n",
      "|     0.8|        -459|\n",
      "|    0.85|       -3068|\n",
      "+--------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's see the totl profit by discount bracket, make sure they are ordered by \n",
    "discount_totProfit = df.groupBy(\"Discount\").agg(sum(\"Profit\").alias(\"total_profit\")).orderBy(\"Discount\")\n",
    "discount_totProfit.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1d76050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|max(Discount)|\n",
      "+-------------+\n",
      "|          0.2|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# what is the value after which we should stop offering discount?\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "df = df.withColumn(\"Discount\", df.Discount.cast(FloatType()))\n",
    "\n",
    "\n",
    "discount_totProfit.filter(discount_totProfit.total_profit >= 0).select(max(\"Discount\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aae94ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+-----------+\n",
      "|    Customer Name|Customer ID|sum(Profit)|\n",
      "+-----------------+-----------+-----------+\n",
      "|     Susan Pistek|   SP-20920|       4960|\n",
      "|    Patrick Jones|   PJ-18835|       3985|\n",
      "|Patrick O'Donnell|   PO-18865|       3771|\n",
      "|    Ellis Ballard|   EB-13840|       3453|\n",
      "|  Mike Gockenbach|   MG-18145|       3142|\n",
      "+-----------------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# who are the top 5 most profitable customers\n",
    "\n",
    "topCustomers = df.groupBy(\"Customer Name\", \"Customer ID\").sum(\"Profit\").orderBy(\"sum(Profit)\", ascending=False)\n",
    "topCustomers.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "277c465a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the rows belonging to those 5 customer names: hint, you may need the collect method \n",
    "\n",
    "top5CustIDs = [i[1] for i in topCustomers.limit(5).collect()]\n",
    "topCustoemrsDF = df.filter(df[\"Customer ID\"].isin(top5CustIDs))\n",
    "\n",
    "# - how many rows are they?\n",
    "\n",
    "topCustoemrsDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5f9d09ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+----------+----------+--------------+-----------+--------------+---------+-----+-------+--------------+------+---------------+---------------+------------+--------------------+------+--------+--------+------+----------------+\n",
      "|Row ID|       Order ID|Order Date| Ship Date|     Ship Mode|Customer ID| Customer Name|  Segment| City|  State|       Country|Region|     Product ID|       Category|Sub-Category|        Product Name| Sales|Quantity|Discount|Profit|without Discount|\n",
      "+------+---------------+----------+----------+--------------+-----------+--------------+---------+-----+-------+--------------+------+---------------+---------------+------------+--------------------+------+--------+--------+------+----------------+\n",
      "|     1|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|OFF-ST-10000988|Office Supplies|     Storage|Fellowes Folders,...|  79.2|       3|     0.0|    39|            79.2|\n",
      "|     2|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|TEC-AC-10004144|     Technology| Accessories|SanDisk Numeric K...|388.92|       7|     0.0|     0|          388.92|\n",
      "|     3|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|OFF-LA-10001915|Office Supplies|      Labels|Avery Legal Exhib...| 35.19|       3|     0.0|    16|           35.19|\n",
      "|     4|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|OFF-ST-10004550|Office Supplies|     Storage|Fellowes Folders,...| 50.94|       2|     0.0|    13|           50.94|\n",
      "|     5|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|TEC-AC-10004068|     Technology| Accessories|Memorex Memory Ca...|307.44|       3|     0.0|    73|          307.44|\n",
      "+------+---------------+----------+----------+--------------+-----------+--------------+---------+-----+-------+--------------+------+---------------+---------------+------------+--------------------+------+--------+--------+------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a new column which is the value of the sale were there not discount applied. Hint: orginal = sales/(1-d)\n",
    "\n",
    "df.withColumn(\"without Discount\", df[\"Sales\"]/(1 - df[\"Discount\"])).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ba0f9aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+----------+----------+--------------+-----------+--------------+---------+-----+-------+--------------+------+---------------+---------------+------------+--------------------+------+--------+--------+------+----------+\n",
      "|Row ID|       Order ID|Order Date| Ship Date|     Ship Mode|Customer ID| Customer Name|  Segment| City|  State|       Country|Region|     Product ID|       Category|Sub-Category|        Product Name| Sales|Quantity|Discount|Profit|differance|\n",
      "+------+---------------+----------+----------+--------------+-----------+--------------+---------+-----+-------+--------------+------+---------------+---------------+------------+--------------------+------+--------+--------+------+----------+\n",
      "|     1|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|OFF-ST-10000988|Office Supplies|     Storage|Fellowes Folders,...|  79.2|       3|     0.0|    39|      79.2|\n",
      "|     2|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|TEC-AC-10004144|     Technology| Accessories|SanDisk Numeric K...|388.92|       7|     0.0|     0|    388.92|\n",
      "|     3|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|OFF-LA-10001915|Office Supplies|      Labels|Avery Legal Exhib...| 35.19|       3|     0.0|    16|     35.19|\n",
      "|     4|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|OFF-ST-10004550|Office Supplies|     Storage|Fellowes Folders,...| 50.94|       2|     0.0|    13|     50.94|\n",
      "|     5|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|TEC-AC-10004068|     Technology| Accessories|Memorex Memory Ca...|307.44|       3|     0.0|    73|    307.44|\n",
      "+------+---------------+----------+----------+--------------+-----------+--------------+---------+-----+-------+--------------+------+---------------+---------------+------------+--------------------+------+--------+--------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate the difference between sales and discount value\n",
    "\n",
    "df.withColumn(\"differance\", df[\"Discount\"]*df[\"without Discount\"]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8e810f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+---------------+\n",
      "|Discount|total_sales|discount_amount|\n",
      "+--------+-----------+---------------+\n",
      "|     0.0|  1522456.0|            0.0|\n",
      "|     0.1|   762412.0|        76241.0|\n",
      "|    0.15|   256321.0|        38448.0|\n",
      "|     0.2|    42612.0|         8522.0|\n",
      "|     0.3|     6137.0|         1841.0|\n",
      "|    0.35|    54160.0|        18956.0|\n",
      "|     0.4|    70087.0|        28035.0|\n",
      "|    0.45|     2546.0|         1146.0|\n",
      "|     0.5|   183734.0|        91867.0|\n",
      "|     0.6|    26429.0|        15857.0|\n",
      "|    0.65|     6580.0|         4277.0|\n",
      "|     0.7|     3657.0|         2560.0|\n",
      "|     0.8|      159.0|          127.0|\n",
      "|    0.85|      797.0|          677.0|\n",
      "+--------+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# how much money did we not gain due to the discounts - per discount bracket?\n",
    "\n",
    "discount_totSales = df.groupBy(\"Discount\").agg(round(sum(\"Sales\")).alias(\"total_sales\")).orderBy(\"Discount\")\n",
    "discount_totSales = discount_totSales.withColumn(\"discount_amount\", \n",
    "                                round(discount_totSales[\"total_sales\"]*discount_totSales[\"Discount\"]))\n",
    "discount_totSales.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "76aca9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+---------------+\n",
      "|Discount|total_sales|discount_amount|\n",
      "+--------+-----------+---------------+\n",
      "|     0.5|   183734.0|        91867.0|\n",
      "+--------+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find the discount bracket which made us not gain the most (dynamically)\n",
    "\n",
    "v = discount_totSales.agg(max(\"discount_amount\")).collect()\n",
    "discount_totSales.filter(discount_totSales[\"discount_amount\"] == v[0][0]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0aa9b685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sum(Profit)|\n",
      "+-----------+\n",
      "|     369970|\n",
      "+-----------+\n",
      "\n",
      "+-----------+\n",
      "|sum(Profit)|\n",
      "+-----------+\n",
      "|     466074|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# what would have been the total profit if we removed all orders from that discount group? \n",
    "\n",
    "before = df.agg(sum(\"Profit\"))\n",
    "after = df.filter(df['Discount'] != 0.5).agg(sum(\"Profit\"))\n",
    "\n",
    "before.show()\n",
    "after.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fca95e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96104"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how much more (or less) profit is that?\n",
    "\n",
    "after.collect()[0][0] - before.collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0fb49200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a temporary table for our superstore table in sql\n",
    "\n",
    "df.createOrReplaceTempView(\"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a23e0bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   10000|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use an SQL query to count the number of rows\n",
    "spark.sql(\"SELECT COUNT(*) FROM df\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8e2cf9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+\n",
      "|       Country|profit_ratio|\n",
      "+--------------+------------+\n",
      "|   Switzerland|        0.29|\n",
      "|       Austria|        0.26|\n",
      "|        Norway|        0.25|\n",
      "|       Belgium|        0.23|\n",
      "|United Kingdom|        0.21|\n",
      "|       Finland|        0.19|\n",
      "|         Spain|        0.19|\n",
      "|       Germany|        0.17|\n",
      "|        France|        0.13|\n",
      "|         Italy|        0.07|\n",
      "|       Ireland|       -0.44|\n",
      "|       Denmark|       -0.49|\n",
      "|   Netherlands|       -0.53|\n",
      "|        Sweden|       -0.57|\n",
      "|      Portugal|       -0.57|\n",
      "+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use an SQL query to calculate the profit ratio for each country: hint, ratio is sum(profit)/sum(sales)\n",
    "\n",
    "profRatDF = spark.sql(\"SELECT Country, round(sum(Profit) / sum(Sales), 2) AS profit_ratio FROM df GROUP BY Country ORDER BY 2 DESC\")\n",
    "profRatDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f8cdd772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United Kingdom\n",
      "Switzerland\n"
     ]
    }
   ],
   "source": [
    "# is the country with the largest profit ratio, the country with the largest profit?\n",
    "\n",
    "topProfDF = spark.sql(\"SELECT Country, sum(Profit) AS profit_ratio FROM df GROUP BY Country ORDER BY 2 DESC\")\n",
    "\n",
    "print(topProfDF.collect()[0][0])\n",
    "print(profRatDF.collect()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7397b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
