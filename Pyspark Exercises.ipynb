{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d867484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18cf8dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/13 12:37:27 WARN Utils: Your hostname, murats-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.68.101 instead (on interface en0)\n",
      "23/02/13 12:37:27 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/13 12:37:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Datamanipulation\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e64796c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.68.101:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Datamanipulation</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x112878be0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cb29770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# read our data - lives in a csv file\n",
    "\n",
    "df = spark.read.option(\"header\",\"true\").csv(\"Sample - EU Superstore.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6899efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Row ID: string (nullable = true)\n",
      " |-- Order ID: string (nullable = true)\n",
      " |-- Order Date: string (nullable = true)\n",
      " |-- Ship Date: string (nullable = true)\n",
      " |-- Ship Mode: string (nullable = true)\n",
      " |-- Customer ID: string (nullable = true)\n",
      " |-- Customer Name: string (nullable = true)\n",
      " |-- Segment: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Product ID: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Sub-Category: string (nullable = true)\n",
      " |-- Product Name: string (nullable = true)\n",
      " |-- Sales: string (nullable = true)\n",
      " |-- Quantity: string (nullable = true)\n",
      " |-- Discount: string (nullable = true)\n",
      " |-- Profit: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c24992ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "795"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"Customer ID\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c800030",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many rows of the EU Superstore dataset have the country being France\n",
    "df.select(\"Country\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "648e5f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+\n",
      "|       Country|sum(Profit)|\n",
      "+--------------+-----------+\n",
      "|       Germany|     106518|\n",
      "|        France|     108070|\n",
      "|       Belgium|      11494|\n",
      "|       Finland|       3873|\n",
      "|         Italy|      19558|\n",
      "|        Norway|       5133|\n",
      "|         Spain|      54054|\n",
      "|   Switzerland|       7201|\n",
      "|       Austria|      21307|\n",
      "|United Kingdom|     111323|\n",
      "+--------------+-----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# of those, how many are profitable?\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "df = df.withColumn(\"Profit\", df.Profit.cast(IntegerType()))\n",
    "\n",
    "byProfit = df.groupBy(\"Country\").sum(\"Profit\")\n",
    "profitable = byProfit.filter(byProfit[\"sum(Profit)\"] > 0)\n",
    "profitable.show()\n",
    "profitable.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca611b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|Discount|\n",
      "+--------+\n",
      "|       0|\n",
      "|     0.1|\n",
      "|    0.15|\n",
      "|     0.2|\n",
      "|     0.3|\n",
      "|    0.35|\n",
      "|     0.4|\n",
      "|    0.45|\n",
      "|     0.5|\n",
      "|     0.6|\n",
      "|    0.65|\n",
      "|     0.7|\n",
      "|     0.8|\n",
      "|    0.85|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how any different discount brackets exist? what are they?\n",
    "brackets = df.select(\"Discount\").distinct().orderBy(\"Discount\")\n",
    "brackets.show()\n",
    "brackets.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2e1f9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|Discount|total_profit|\n",
      "+--------+------------+\n",
      "|       0|      380803|\n",
      "|     0.1|      126392|\n",
      "|    0.15|       24623|\n",
      "|     0.2|        2174|\n",
      "|     0.3|        -756|\n",
      "|    0.35|       -9108|\n",
      "|     0.4|      -21259|\n",
      "|    0.45|       -1102|\n",
      "|     0.5|      -96104|\n",
      "|     0.6|      -20460|\n",
      "|    0.65|       -6213|\n",
      "|     0.7|       -5493|\n",
      "|     0.8|        -459|\n",
      "|    0.85|       -3068|\n",
      "+--------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's see the totl profit by discount bracket, make sure they are ordered by \n",
    "discount_totProfit = df.groupBy(\"Discount\").agg(sum(\"Profit\").alias(\"total_profit\")).orderBy(\"Discount\")\n",
    "discount_totProfit.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d1d76050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|max(Discount)|\n",
      "+-------------+\n",
      "|          0.2|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# what is the value after which we should stop offering discount?\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "df = df.withColumn(\"Discount\", df.Discount.cast(FloatType()))\n",
    "\n",
    "\n",
    "discount_totProfit.filter(discount_totProfit.total_profit >= 0).select(max(\"Discount\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "aae94ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+\n",
      "|    Customer Name|Customer ID|\n",
      "+-----------------+-----------+\n",
      "|    Patrick Jones|   PJ-18835|\n",
      "|Elpida Rittenbach|   ER-13855|\n",
      "|  Mike Gockenbach|   MG-18145|\n",
      "|     James Galang|   JG-15160|\n",
      "|    Ellis Ballard|   EB-13840|\n",
      "+-----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# who are the top 5 most profitable customers\n",
    "\n",
    "topCustomers = df.orderBy(\"Profit\", ascending=False).select(\"Customer Name\", \"Customer ID\")\n",
    "topCustomers.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "277c465a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the rows belonging to those 5 customer names: hint, you may need the collect method \n",
    "\n",
    "top5CustIDs = [i[0] for i in topCustomers.limit(5).select(\"Customer ID\").collect()]\n",
    "topCustoemrsDF = df.filter(df[\"Customer ID\"].isin(top5CustIDs))\n",
    "\n",
    "# - how many rows are they?\n",
    "\n",
    "topCustoemrsDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5f9d09ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+----------+----------+--------------+-----------+--------------+---------+-----+-------+--------------+------+---------------+---------------+------------+--------------------+------+--------+--------+------+----------------+\n",
      "|Row ID|       Order ID|Order Date| Ship Date|     Ship Mode|Customer ID| Customer Name|  Segment| City|  State|       Country|Region|     Product ID|       Category|Sub-Category|        Product Name| Sales|Quantity|Discount|Profit|without Discount|\n",
      "+------+---------------+----------+----------+--------------+-----------+--------------+---------+-----+-------+--------------+------+---------------+---------------+------------+--------------------+------+--------+--------+------+----------------+\n",
      "|     1|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|OFF-ST-10000988|Office Supplies|     Storage|Fellowes Folders,...|  79.2|       3|     0.0|    39|            79.2|\n",
      "|     2|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|TEC-AC-10004144|     Technology| Accessories|SanDisk Numeric K...|388.92|       7|     0.0|     0|          388.92|\n",
      "|     3|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|OFF-LA-10001915|Office Supplies|      Labels|Avery Legal Exhib...| 35.19|       3|     0.0|    16|           35.19|\n",
      "|     4|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|OFF-ST-10004550|Office Supplies|     Storage|Fellowes Folders,...| 50.94|       2|     0.0|    13|           50.94|\n",
      "|     5|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|TEC-AC-10004068|     Technology| Accessories|Memorex Memory Ca...|307.44|       3|     0.0|    73|          307.44|\n",
      "+------+---------------+----------+----------+--------------+-----------+--------------+---------+-----+-------+--------------+------+---------------+---------------+------------+--------------------+------+--------+--------+------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a new column which is the value of the sale were there not discount applied. Hint: orginal = sales/(1-d)\n",
    "\n",
    "df.withColumn(\"without Discount\", df[\"Sales\"]/(1 - df[\"Discount\"])).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ba0f9aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+----------+----------+--------------+-----------+--------------+---------+-----+-------+--------------+------+---------------+---------------+------------+--------------------+------+--------+--------+------+----------+\n",
      "|Row ID|       Order ID|Order Date| Ship Date|     Ship Mode|Customer ID| Customer Name|  Segment| City|  State|       Country|Region|     Product ID|       Category|Sub-Category|        Product Name| Sales|Quantity|Discount|Profit|differance|\n",
      "+------+---------------+----------+----------+--------------+-----------+--------------+---------+-----+-------+--------------+------+---------------+---------------+------------+--------------------+------+--------+--------+------+----------+\n",
      "|     1|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|OFF-ST-10000988|Office Supplies|     Storage|Fellowes Folders,...|  79.2|       3|     0.0|    39|      79.2|\n",
      "|     2|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|TEC-AC-10004144|     Technology| Accessories|SanDisk Numeric K...|388.92|       7|     0.0|     0|    388.92|\n",
      "|     3|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|OFF-LA-10001915|Office Supplies|      Labels|Avery Legal Exhib...| 35.19|       3|     0.0|    16|     35.19|\n",
      "|     4|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|OFF-ST-10004550|Office Supplies|     Storage|Fellowes Folders,...| 50.94|       2|     0.0|    13|     50.94|\n",
      "|     5|ES-2017-1311038|07/02/2017|11/02/2017|Standard Class|   AS-10045|Aaron Smayling|Corporate|Leeds|England|United Kingdom| North|TEC-AC-10004068|     Technology| Accessories|Memorex Memory Ca...|307.44|       3|     0.0|    73|    307.44|\n",
      "+------+---------------+----------+----------+--------------+-----------+--------------+---------+-----+-------+--------------+------+---------------+---------------+------------+--------------------+------+--------+--------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate the difference between sales and discount value\n",
    "\n",
    "df.withColumn(\"differance\", df[\"Sales\"]- (df[\"Discount\"]*df[\"Sales\"])).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8e810f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+---------------+\n",
      "|Discount|total_sales|discount_amount|\n",
      "+--------+-----------+---------------+\n",
      "|     0.0|  1522456.0|            0.0|\n",
      "|     0.1|   762412.0|        76241.0|\n",
      "|    0.15|   256321.0|        38448.0|\n",
      "|     0.2|    42612.0|         8522.0|\n",
      "|     0.3|     6137.0|         1841.0|\n",
      "|    0.35|    54160.0|        18956.0|\n",
      "|     0.4|    70087.0|        28035.0|\n",
      "|    0.45|     2546.0|         1146.0|\n",
      "|     0.5|   183734.0|        91867.0|\n",
      "|     0.6|    26429.0|        15857.0|\n",
      "|    0.65|     6580.0|         4277.0|\n",
      "|     0.7|     3657.0|         2560.0|\n",
      "|     0.8|      159.0|          127.0|\n",
      "|    0.85|      797.0|          677.0|\n",
      "+--------+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# how much money did we not gain due to the discounts - per discount bracket?\n",
    "\n",
    "discount_totSales = df.groupBy(\"Discount\").agg(round(sum(\"Sales\")).alias(\"total_sales\")).orderBy(\"Discount\")\n",
    "discount_totSales = discount_totSales.withColumn(\"discount_amount\", \n",
    "                                round(discount_totSales[\"total_sales\"]*discount_totSales[\"Discount\"]))\n",
    "discount_totSales.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "76aca9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+---------------+\n",
      "|Discount|total_sales|discount_amount|\n",
      "+--------+-----------+---------------+\n",
      "|     0.5|   183734.0|        91867.0|\n",
      "+--------+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find the discount bracket which made us not gain the most (dynamically)\n",
    "\n",
    "v = discount_totSales.agg(max(\"discount_amount\")).collect()\n",
    "discount_totSales.filter(discount_totSales[\"discount_amount\"] == v[0][0]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0aa9b685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sum(Profit)|\n",
      "+-----------+\n",
      "|     369970|\n",
      "+-----------+\n",
      "\n",
      "+-----------+\n",
      "|sum(Profit)|\n",
      "+-----------+\n",
      "|     466074|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# what would have been the total profit if we removed all orders from that discount group? \n",
    "\n",
    "before = df.agg(sum(\"Profit\"))\n",
    "after = df.filter(df['Discount'] != 0.5).agg(sum(\"Profit\"))\n",
    "\n",
    "before.show()\n",
    "after.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fca95e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96104"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how much more (or less) profit is that?\n",
    "\n",
    "after.collect()[0][0] - before.collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0fb49200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a temporary table for our superstore table in sql\n",
    "\n",
    "df.createOrReplaceTempView(\"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a23e0bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   10000|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use an SQL query to count the number of rows\n",
    "spark.sql(\"SELECT COUNT(*) FROM df\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8e2cf9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+\n",
      "|       Country|profit_ratio|\n",
      "+--------------+------------+\n",
      "|   Switzerland|        0.29|\n",
      "|       Austria|        0.26|\n",
      "|        Norway|        0.25|\n",
      "|       Belgium|        0.23|\n",
      "|United Kingdom|        0.21|\n",
      "|       Finland|        0.19|\n",
      "|         Spain|        0.19|\n",
      "|       Germany|        0.17|\n",
      "|        France|        0.13|\n",
      "|         Italy|        0.07|\n",
      "|       Ireland|       -0.44|\n",
      "|       Denmark|       -0.49|\n",
      "|   Netherlands|       -0.53|\n",
      "|        Sweden|       -0.57|\n",
      "|      Portugal|       -0.57|\n",
      "+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use an SQL query to calculate the profit ratio for each country: hint, ratio is sum(profit)/sum(sales)\n",
    "\n",
    "profRatDF = spark.sql(\"SELECT Country, round(sum(Profit) / sum(Sales), 2) AS profit_ratio FROM df GROUP BY Country ORDER BY 2 DESC\")\n",
    "profRatDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f8cdd772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United Kingdom\n",
      "Switzerland\n"
     ]
    }
   ],
   "source": [
    "# is the country with the largest profit ratio, the country with the largest profit?\n",
    "\n",
    "topProfDF = spark.sql(\"SELECT Country, sum(Profit) AS profit_ratio FROM df GROUP BY Country ORDER BY 2 DESC\")\n",
    "\n",
    "print(topProfDF.collect()[0][0])\n",
    "print(profRatDF.collect()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7397b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
